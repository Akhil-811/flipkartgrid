{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmdk_SXmDnl-",
        "outputId": "53b5b140-ae5f-4319-9c72-c28959cd49bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.1+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (10.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.24.0)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.6)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2024.6.1)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n",
            "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (912 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.2/912.2 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.8/286.8 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, ninja, easyocr\n",
            "Successfully installed easyocr-1.7.2 ninja-1.11.1.1 pyclipper-1.3.0.post6 python-bidi-0.6.3\n"
          ]
        }
      ],
      "source": [
        "pip install easyocr\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import easyocr\n",
        "\n",
        "# Initialize the EasyOCR Reader (supports multiple languages, e.g., ['en'] for English)\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Define the path to your dataset\n",
        "dataset_path = '/content/drive/MyDrive/dataset'\n",
        "\n",
        "# Function to extract text from front and back images of a product\n",
        "def extract_product_details(product_folder):\n",
        "    front_image_path = os.path.join(product_folder, 'front.jpg')  # Updated to .jpg format\n",
        "    back_image_path = os.path.join(product_folder, 'back.jpg')    # Updated to .jpg format\n",
        "\n",
        "    # Check if the images exist\n",
        "    if not os.path.exists(front_image_path) or not os.path.exists(back_image_path):\n",
        "        print(f\"Images missing in {product_folder}\")\n",
        "        return None\n",
        "\n",
        "    # Reading text from front and back images\n",
        "    front_text = reader.readtext(front_image_path, detail=0)  # detail=0 returns just the text\n",
        "    back_text = reader.readtext(back_image_path, detail=0)\n",
        "\n",
        "    # Combining text from both images\n",
        "    combined_text = {\n",
        "        \"product_name\": os.path.basename(product_folder),\n",
        "        \"front_image_text\": front_text,\n",
        "        \"back_image_text\": back_text\n",
        "    }\n",
        "\n",
        "    return combined_text\n",
        "\n",
        "# Iterate through the dataset and process each product folder\n",
        "def process_dataset(dataset_path):\n",
        "    product_details = []\n",
        "\n",
        "    # List all product folders\n",
        "    for product_name in os.listdir(dataset_path):\n",
        "        product_folder = os.path.join(dataset_path, product_name)\n",
        "        if os.path.isdir(product_folder):\n",
        "            details = extract_product_details(product_folder)\n",
        "            if details:\n",
        "                product_details.append(details)\n",
        "\n",
        "    return product_details\n",
        "\n",
        "# Run the function on your dataset\n",
        "product_data = process_dataset(dataset_path)\n",
        "\n",
        "# Example of how you can display the extracted data\n",
        "for product in product_data:\n",
        "    print(f\"Product: {product['product_name']}\")\n",
        "    print(f\"Front Image Text: {product['front_image_text']}\")\n",
        "    print(f\"Back Image Text: {product['back_image_text']}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ua2QPFXzbqa",
        "outputId": "c2d25841-1d4c-41b1-c76a-5234ca996f0f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% CompleteImages missing in /content/drive/MyDrive/dataset/complain\n",
            "Product: bread\n",
            "Front Image Text: ['Huvzaa|', 'ZERO', 'TRANS', 'FAT', '4GLIS,', 'FIBER HELPS', 'DIGESTION', 'OVE)', 'BROWN', 'HIGH', 'FIBRE BREAD', 'FRESHLY BAKED']\n",
            "Back Image Text: ['Huvzaa|', 'COMMODITY NAME: BROWN BREAD', 'NUTRITONAL INFORMATION', '7.1.1 [Bread and Rolls]', 'PER 100g PRODUCT (APPROX ,', 'INGREDIENTS: Weat Roulma da]', 'Waler   Yeast  Whzat', 'Eneagy', 'Zjoacal', 'Ala(5%0} Sugar', 'Edibe? Conmcn Salt, Ecble Vegetatle', 'carbohydaATES', '53.t1g', 'Ois (Palm}', 'Guren', 'Bran, Roasted Cerea', 'Qf WHICH SUGARS', '2.059', 'Flour;   Soya  Flur;   Class', 'Preservabive/2821,', 'Acidily', 'Reg lator (260]  Emulstiers [471, 472e, 481f], Improve 5', 'SATURATED FAT', '0,26g', '[170 @,510,923,1100] And  Antiowdart (3001.', 'TRANS FaT', 'PROTEIN', '7,930', '(NUMBERS IN BRACKETS ARE AS PER', 'dietary fiber', 'INTERNATIONAL NUMBERING SYSTEM)', 'ALLERGEN DECLARATION: PRODUCT CONTAINS WHEAT FLOUR', '(GLUTEN) AND SOYA FLOUR AS ALLERGENS', 'NET WEIGHT', 'MRP', 'alS', 'USE BY DATE:', 'LOT NO:', 'fssai', 'Lic No ', '10013022002023', 'MANUFACTURED BY:', '8/l903007ll02 923-', 'BAKE BEST FOODS PRIVATE LIMITED, Survey No. 724/1/58/59,', 'Vadval,', 'Taluka   Khalapur   (Khopoli) , Distt   Raigad,', 'Maharashtra, India - 410203.', 'For any Feedback/Complaint,', 'Please', 'our', 'Executive', 'Customer Care No. 1-8001029163', 'ofTolo.Freea;', 'Mrs_', 'Bectors   Food   Specialities  Ltd.', 'Plot  No.', 'Udyog Vihar;', 'Greater   Noida', 'Distt.', 'Gautam   Budh', '|Nagar (U P), India-201 306 or E-mail: bakery@cremica in,', 'Website-', 'WWW', 'englishoven com, Fb: @English Oven', 'STORE IN COOL, DRY AND HYGIENIC', 'CONDITIONS, AWAY FROM SUNLIGHT', 'Med', 'Wneat', '200g', 'Village', 'call']\n",
            "--------------------------------------------------\n",
            "Product: cheese\n",
            "Front Image Text: ['BRITANNIA', 'CHEESE', 'PROTEIN', 'Laughing Cw', 'CUBES']\n",
            "Back Image Text: ['Ta7a', 'MeTe', 'ElnenMMAADAOAMDTN NSCAAlLN', 'HeNN', 'Ebacul (uciudtd Mmlu srutad Mutta', 'TicNo: 70013022000281', 'Mntodm', 'Wl eme', 'MEouM', '3109', 'fssai', 'LEWb', 'UZNa 10014031001210', 'DeMbloluab', 'H#: enaehmeonmatt', 'WqunlayiHi-', 'Snngceonncs ennnn', 'mbehl', 'ate', 'Ecren akad', 'Ialubal', 'Thaant']\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import easyocr\n",
        "import re\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta  # To add months easily\n",
        "\n",
        "# Initialize the EasyOCR Reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Function to extract MRP, expiry date, and best-before details\n",
        "def extract_mrp_and_expiry(text):\n",
        "    mrp = None\n",
        "    expiry_date = None\n",
        "    packing_date = None\n",
        "    best_before_months = None\n",
        "\n",
        "    # Regex patterns\n",
        "    mrp_pattern = r'MRP\\s*:?[\\s₹]*\\d+\\.?\\d*'  # MRP pattern\n",
        "    expiry_pattern = r'(expiry|exp|use by|best before)\\s*:?[\\w\\s]*\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{2,4}'  # Direct expiry date\n",
        "    best_before_pattern = r'best before\\s*(\\d+)\\s*months'  # Best before N months\n",
        "    packing_date_pattern = r'packing date\\s*:?[\\w\\s]*\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{2,4}'  # Packing date\n",
        "\n",
        "    # Join the text into a single string for regex matching\n",
        "    full_text = \" \".join(text).lower()\n",
        "\n",
        "    # Search for MRP\n",
        "    mrp_match = re.search(mrp_pattern, full_text)\n",
        "    if mrp_match:\n",
        "        mrp = mrp_match.group()\n",
        "\n",
        "    # Search for direct expiry date\n",
        "    expiry_match = re.search(expiry_pattern, full_text)\n",
        "    if expiry_match:\n",
        "        expiry_date = expiry_match.group()\n",
        "\n",
        "    # Search for 'Best before N months'\n",
        "    best_before_match = re.search(best_before_pattern, full_text)\n",
        "    if best_before_match:\n",
        "        best_before_months = int(best_before_match.group(1))  # Extract number of months\n",
        "\n",
        "    # Search for packing date\n",
        "    packing_date_match = re.search(packing_date_pattern, full_text)\n",
        "    if packing_date_match:\n",
        "        packing_date_str = packing_date_match.group()\n",
        "        # Try to parse the packing date (e.g., 'Packing Date: 12/12/2023')\n",
        "        packing_date = parse_date_from_string(packing_date_str)\n",
        "\n",
        "    return mrp, expiry_date, best_before_months, packing_date\n",
        "\n",
        "# Helper function to parse a date from a string\n",
        "def parse_date_from_string(date_str):\n",
        "    try:\n",
        "        # Try to parse in different formats (dd/mm/yyyy, dd-mm-yyyy, etc.)\n",
        "        return datetime.strptime(re.search(r'\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{2,4}', date_str).group(), '%d/%m/%Y')\n",
        "    except ValueError:\n",
        "        try:\n",
        "            return datetime.strptime(re.search(r'\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{2,4}', date_str).group(), '%d-%m-%Y')\n",
        "        except ValueError:\n",
        "            return None\n",
        "\n",
        "# Function to calculate expiry date from packing date and 'Best before N months'\n",
        "def calculate_expiry_from_best_before(packing_date, best_before_months):\n",
        "    if packing_date and best_before_months:\n",
        "        # Add N months to the packing date\n",
        "        return packing_date + relativedelta(months=best_before_months)\n",
        "    return None\n",
        "\n",
        "# Function to extract text from front and back images of a product\n",
        "def extract_product_details(product_folder):\n",
        "    front_image_path = os.path.join(product_folder, 'front.jpg')\n",
        "    back_image_path = os.path.join(product_folder, 'back.jpg')\n",
        "\n",
        "    if not os.path.exists(front_image_path) or not os.path.exists(back_image_path):\n",
        "        print(f\"Images missing in {product_folder}\")\n",
        "        return None\n",
        "\n",
        "    # Reading text from front and back images\n",
        "    front_text = reader.readtext(front_image_path, detail=0)\n",
        "    back_text = reader.readtext(back_image_path, detail=0)\n",
        "\n",
        "    # Extract MRP, expiry date, best-before details from both front and back\n",
        "    mrp_front, expiry_front, best_before_front, packing_date_front = extract_mrp_and_expiry(front_text)\n",
        "    mrp_back, expiry_back, best_before_back, packing_date_back = extract_mrp_and_expiry(back_text)\n",
        "\n",
        "    # Choose MRP from front or back\n",
        "    mrp = mrp_front if mrp_front else mrp_back\n",
        "\n",
        "    # Choose direct expiry date if available\n",
        "    expiry_date = expiry_front if expiry_front else expiry_back\n",
        "\n",
        "    # If no direct expiry date, calculate from best-before and packing date\n",
        "    if not expiry_date:\n",
        "        packing_date = packing_date_front if packing_date_front else packing_date_back\n",
        "        best_before_months = best_before_front if best_before_front else best_before_back\n",
        "        expiry_date = calculate_expiry_from_best_before(packing_date, best_before_months)\n",
        "\n",
        "    # Combine details\n",
        "    combined_details = {\n",
        "        \"product_name\": os.path.basename(product_folder),\n",
        "        \"front_image_text\": front_text,\n",
        "        \"back_image_text\": back_text,\n",
        "        \"mrp\": mrp,\n",
        "        \"expiry_date\": expiry_date.strftime('%d/%m/%Y') if expiry_date else None\n",
        "    }\n",
        "\n",
        "    return combined_details\n",
        "\n",
        "# Iterate through the dataset and process each product folder\n",
        "def process_dataset(dataset_path):\n",
        "    product_details = []\n",
        "\n",
        "    # List all product folders\n",
        "    for product_name in os.listdir(dataset_path):\n",
        "        product_folder = os.path.join(dataset_path, product_name)\n",
        "        if os.path.isdir(product_folder):\n",
        "            details = extract_product_details(product_folder)\n",
        "            if details:\n",
        "                product_details.append(details)\n",
        "\n",
        "    return product_details\n",
        "\n",
        "# Run the function on your dataset\n",
        "product_data = process_dataset(dataset_path)\n",
        "\n",
        "# Example of how you can display the extracted data\n",
        "for product in product_data:\n",
        "    print(f\"Product: {product['product_name']}\")\n",
        "    print(f\"Front Image Text: {product['front_image_text']}\")\n",
        "    print(f\"Back Image Text: {product['back_image_text']}\")\n",
        "    print(f\"MRP: {product['mrp']}\")\n",
        "    print(f\"Expiry Date: {product['expiry_date']}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOH8hyMB5JEz",
        "outputId": "69793a1f-9d62-4051-9a80-48e5607219f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images missing in /content/drive/MyDrive/dataset/complain\n",
            "Product: bread\n",
            "Front Image Text: ['Huvzaa|', 'ZERO', 'TRANS', 'FAT', '4GLIS,', 'FIBER HELPS', 'DIGESTION', 'OVE)', 'BROWN', 'HIGH', 'FIBRE BREAD', 'FRESHLY BAKED']\n",
            "Back Image Text: ['Huvzaa|', 'COMMODITY NAME: BROWN BREAD', 'NUTRITONAL INFORMATION', '7.1.1 [Bread and Rolls]', 'PER 100g PRODUCT (APPROX ,', 'INGREDIENTS: Weat Roulma da]', 'Waler   Yeast  Whzat', 'Eneagy', 'Zjoacal', 'Ala(5%0} Sugar', 'Edibe? Conmcn Salt, Ecble Vegetatle', 'carbohydaATES', '53.t1g', 'Ois (Palm}', 'Guren', 'Bran, Roasted Cerea', 'Qf WHICH SUGARS', '2.059', 'Flour;   Soya  Flur;   Class', 'Preservabive/2821,', 'Acidily', 'Reg lator (260]  Emulstiers [471, 472e, 481f], Improve 5', 'SATURATED FAT', '0,26g', '[170 @,510,923,1100] And  Antiowdart (3001.', 'TRANS FaT', 'PROTEIN', '7,930', '(NUMBERS IN BRACKETS ARE AS PER', 'dietary fiber', 'INTERNATIONAL NUMBERING SYSTEM)', 'ALLERGEN DECLARATION: PRODUCT CONTAINS WHEAT FLOUR', '(GLUTEN) AND SOYA FLOUR AS ALLERGENS', 'NET WEIGHT', 'MRP', 'alS', 'USE BY DATE:', 'LOT NO:', 'fssai', 'Lic No ', '10013022002023', 'MANUFACTURED BY:', '8/l903007ll02 923-', 'BAKE BEST FOODS PRIVATE LIMITED, Survey No. 724/1/58/59,', 'Vadval,', 'Taluka   Khalapur   (Khopoli) , Distt   Raigad,', 'Maharashtra, India - 410203.', 'For any Feedback/Complaint,', 'Please', 'our', 'Executive', 'Customer Care No. 1-8001029163', 'ofTolo.Freea;', 'Mrs_', 'Bectors   Food   Specialities  Ltd.', 'Plot  No.', 'Udyog Vihar;', 'Greater   Noida', 'Distt.', 'Gautam   Budh', '|Nagar (U P), India-201 306 or E-mail: bakery@cremica in,', 'Website-', 'WWW', 'englishoven com, Fb: @English Oven', 'STORE IN COOL, DRY AND HYGIENIC', 'CONDITIONS, AWAY FROM SUNLIGHT', 'Med', 'Wneat', '200g', 'Village', 'call']\n",
            "MRP: None\n",
            "Expiry Date: None\n",
            "--------------------------------------------------\n",
            "Product: cheese\n",
            "Front Image Text: ['BRITANNIA', 'CHEESE', 'PROTEIN', 'Laughing Cw', 'CUBES']\n",
            "Back Image Text: ['Ta7a', 'MeTe', 'ElnenMMAADAOAMDTN NSCAAlLN', 'HeNN', 'Ebacul (uciudtd Mmlu srutad Mutta', 'TicNo: 70013022000281', 'Mntodm', 'Wl eme', 'MEouM', '3109', 'fssai', 'LEWb', 'UZNa 10014031001210', 'DeMbloluab', 'H#: enaehmeonmatt', 'WqunlayiHi-', 'Snngceonncs ennnn', 'mbehl', 'ate', 'Ecren akad', 'Ialubal', 'Thaant']\n",
            "MRP: None\n",
            "Expiry Date: None\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlAc2ziU-PYH",
        "outputId": "4e9ae88c-1117-48cb-eab8-6977f1081bf8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 2s (2,957 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123629 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr-eng"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj7OzKmB-4Nu",
        "outputId": "5f524df1-e2ec-40ac-bdd8-51aa19941c8e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr-eng is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "tesseract-ocr-eng set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pytesseract\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Pre-process the images to improve OCR accuracy\n",
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply thresholding to clean up the image\n",
        "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
        "    return thresh\n",
        "\n",
        "# Extract text using Tesseract OCR\n",
        "def extract_text(image_path):\n",
        "    processed_img = preprocess_image(image_path)\n",
        "    text = pytesseract.image_to_string(processed_img)\n",
        "    return text\n",
        "\n",
        "# Function to find MRP, manufacturing, and expiry date\n",
        "def find_mrp_and_dates(text):\n",
        "    mrp_pattern = re.compile(r'Rs\\.\\s?(\\d+\\.?\\d*)', re.IGNORECASE)\n",
        "    date_pattern = re.compile(r'(\\d{2}/\\d{2}/\\d{2,4})')\n",
        "    best_before_pattern = re.compile(r'Best\\s+before\\s+(\\d+)\\s+months', re.IGNORECASE)\n",
        "\n",
        "    # Find all matches\n",
        "    mrp_match = mrp_pattern.search(text)\n",
        "    dates = date_pattern.findall(text)\n",
        "    best_before_match = best_before_pattern.search(text)\n",
        "\n",
        "    mrp = None\n",
        "    manufacturing_date = None\n",
        "    expiry_date = None\n",
        "\n",
        "    if mrp_match:\n",
        "        mrp = mrp_match.group(1)\n",
        "\n",
        "    # Check for expiry and manufacturing dates in normal format\n",
        "    if len(dates) >= 2:\n",
        "        manufacturing_date = dates[0]\n",
        "        expiry_date = dates[1]\n",
        "\n",
        "    # Handle \"best before n months\" case\n",
        "    if best_before_match and manufacturing_date:\n",
        "        months = int(best_before_match.group(1))\n",
        "        try:\n",
        "            manu_date_obj = datetime.strptime(manufacturing_date, '%d/%m/%y')\n",
        "            expiry_date = (manu_date_obj + timedelta(days=months*30)).strftime('%d/%m/%Y')\n",
        "        except ValueError:\n",
        "            print(f\"Error processing manufacturing date: {manufacturing_date}\")\n",
        "\n",
        "    return {\n",
        "        \"MRP\": mrp,\n",
        "        \"Manufacturing Date\": manufacturing_date,\n",
        "        \"Expiry Date\": expiry_date\n",
        "    }\n",
        "\n",
        "# Process a product directory containing front and back images\n",
        "def process_product(product_dir):\n",
        "    front_image_path = os.path.join(product_dir, \"front.jpg\")\n",
        "    back_image_path = os.path.join(product_dir, \"back.jpg\")\n",
        "\n",
        "    # Check if both images exist\n",
        "    if not os.path.exists(front_image_path) or not os.path.exists(back_image_path):\n",
        "        print(f\"Missing images for product {product_dir}\")\n",
        "        return None\n",
        "\n",
        "    # Extract text from both front and back images\n",
        "    front_text = extract_text(front_image_path)\n",
        "    back_text = extract_text(back_image_path)\n",
        "\n",
        "    # Combine text and find details\n",
        "    combined_text = front_text + \" \" + back_text\n",
        "    product_details = find_mrp_and_dates(combined_text)\n",
        "\n",
        "    return product_details\n",
        "\n",
        "# Main function to process the dataset\n",
        "def process_dataset(dataset_dir):\n",
        "    for product_name in os.listdir(dataset_dir):\n",
        "        product_dir = os.path.join(dataset_dir, product_name)\n",
        "        if os.path.isdir(product_dir):\n",
        "            print(f\"Processing product: {product_name}\")\n",
        "            details = process_product(product_dir)\n",
        "            if details:\n",
        "                print(f\"Details for {product_name}:\")\n",
        "                print(details)\n",
        "            else:\n",
        "                print(f\"No details extracted for {product_name}\")\n",
        "\n",
        "# Example: Run on the dataset directory\n",
        "dataset_dir = \"/content/drive/MyDrive/dataset\"  # Modify this path to your actual dataset\n",
        "process_dataset(dataset_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcBdtQGF8SlJ",
        "outputId": "7fa1d157-9a91-4649-d4d8-8500def8e761"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing product: bread\n",
            "Details for bread:\n",
            "{'MRP': None, 'Manufacturing Date': None, 'Expiry Date': None}\n",
            "Processing product: cheese\n",
            "Details for cheese:\n",
            "{'MRP': None, 'Manufacturing Date': None, 'Expiry Date': None}\n",
            "Processing product: complain\n",
            "Missing images for product /content/drive/MyDrive/dataset/complain\n",
            "No details extracted for complain\n",
            "Processing product: mutton masala\n",
            "Missing images for product /content/drive/MyDrive/dataset/mutton masala\n",
            "No details extracted for mutton masala\n"
          ]
        }
      ]
    }
  ]
}